{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Setup + Document Loading\n",
    "\n",
    "**Goal**: Load DataFlow's enterprise documents for RAG system\n",
    "\n",
    "\n",
    "## Requirements\n",
    "```\n",
    "langchain==0.1.0\n",
    "langchain-community==0.0.13\n",
    "faiss-cpu==1.7.4\n",
    "sentence-transformers==2.2.2\n",
    "pandas==2.0.3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:10:30.692300Z",
     "start_time": "2025-09-24T11:10:30.634611Z"
    }
   },
   "source": [
    "# Imports and setup\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from langchain.document_loaders import TextLoader, CSVLoader, JSONLoader, UnstructuredMarkdownLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Path to enterprise documents\n",
    "KNOWLEDGE_BASE_PATH = Path(\"./enterprise_knowledge_base\")\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Documents"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:11:02.771607Z",
     "start_time": "2025-09-24T11:11:02.647524Z"
    }
   },
   "source": [
    "def load_enterprise_documents(base_path: Path) -> List[Document]:\n",
    "    \"\"\"Load all documents recursively with proper metadata\"\"\"\n",
    "    \n",
    "    all_docs = []\n",
    "    \n",
    "    print(\" Loading DataFlow's documents...\")\n",
    "    \n",
    "    # Process each department folder\n",
    "    for dept_path in base_path.iterdir():\n",
    "        if not dept_path.is_dir():\n",
    "            continue\n",
    "            \n",
    "        department = dept_path.name\n",
    "        print(f\" {department}...\")\n",
    "        \n",
    "        # Get ALL files recursively\n",
    "        files = [f for f in dept_path.rglob(\"*\") if f.is_file()]\n",
    "        \n",
    "        for file_path in files:\n",
    "            try:\n",
    "                # Choose loader by extension\n",
    "                ext = file_path.suffix.lower()\n",
    "                if ext == '.csv':\n",
    "                    loader = CSVLoader(str(file_path))\n",
    "                elif ext == '.json':\n",
    "                    loader = JSONLoader(str(file_path), jq_schema='.', text_content=False)\n",
    "                elif ext == '.md':\n",
    "                    loader = UnstructuredMarkdownLoader(str(file_path))\n",
    "                else:\n",
    "                    loader = TextLoader(str(file_path), encoding='utf-8')\n",
    "                \n",
    "                # Load and add metadata\n",
    "                docs = loader.load()\n",
    "                for doc in docs:\n",
    "                    doc.metadata.update({\n",
    "                        \"department\": department,\n",
    "                        \"source_file\": file_path.name,\n",
    "                        \"file_type\": ext\n",
    "                    })\n",
    "                \n",
    "                all_docs.extend(docs)\n",
    "                rel_path = file_path.relative_to(dept_path)\n",
    "                print(f\"    {rel_path}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   {file_path.name}: {str(e)[:30]}...\")\n",
    "    \n",
    "    # Quick summary\n",
    "    departments = set(doc.metadata['department'] for doc in all_docs)\n",
    "    total_chars = sum(len(doc.page_content) for doc in all_docs)\n",
    "    \n",
    "    print(f\"\\n LOADED: {len(all_docs)} documents from {len(departments)} departments\")\n",
    "    print(f\"Content: {total_chars:,} characters\")\n",
    "    print(f\" Departments: {', '.join(sorted(departments))}\")\n",
    "    \n",
    "    return all_docs\n",
    "\n",
    "# Load all documents\n",
    "documents = load_enterprise_documents(KNOWLEDGE_BASE_PATH)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading DataFlow's documents...\n",
      " business_data...\n",
      "   billing_and_pricing.csv: Error loading enterprise_knowl...\n",
      "   customer_analytics.csv: Error loading enterprise_knowl...\n",
      "    integration_partners.csv\n",
      " customer_facing...\n",
      "   api_documentation.json: jq package not found, please i...\n",
      "    competitive_analysis.txt\n",
      "    product_user_guide.markdown\n",
      "    terms_of_service.markdown\n",
      "    troubleshooting_guide.txt\n",
      " internal_operations...\n",
      "    hr_policies/employee_handbook.txt\n",
      "   onboarding_checklist.json: jq package not found, please i...\n",
      "   release_notes.json: jq package not found, please i...\n",
      "   sales_playbook.json: jq package not found, please i...\n",
      "    support_operations/customer_support_procedures.markdown\n",
      "    support_operations/system_architecture.markdown\n",
      " legal_compliance...\n",
      "    compliance_certifications.csv\n",
      "    privacy_policy.txt\n",
      "    security_policies.txt\n",
      "    terms_of_service.markdown\n",
      "\n",
      " LOADED: 85 documents from 4 departments\n",
      "Content: 167,546 characters\n",
      " Departments: business_data, customer_facing, internal_operations, legal_compliance\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:11:10.178624Z",
     "start_time": "2025-09-24T11:11:10.164639Z"
    }
   },
   "source": [
    "# Quick validation\n",
    "print(\"ðŸ” Validation:\")\n",
    "print(f\"   Documents: {len(documents)} (target: 20+)\")\n",
    "print(f\"   Departments: {len(set(doc.metadata['department'] for doc in documents))} (target: 4)\")\n",
    "print(f\"   Content: {sum(len(doc.page_content) for doc in documents):,} chars (target: 10,000+)\")\n",
    "\n",
    "if len(documents) >= 15:\n",
    "    print(\"\\n SUCCESS! Ready for Part 2: Text Chunking\")\n",
    "else:\n",
    "    print(\"\\n Low document count - check folder structure\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Validation:\n",
      "   Documents: 85 (target: 20+)\n",
      "   Departments: 4 (target: 4)\n",
      "   Content: 167,546 chars (target: 10,000+)\n",
      "\n",
      " SUCCESS! Ready for Part 2: Text Chunking\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Text Chunking\n",
    "\n",
    "**Goal**: Transform 212 documents into optimally-sized chunks for RAG\n",
    "**Why Critical**: Bad chunking = bad RAG responses. Good chunking = accurate answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:11:13.401959Z",
     "start_time": "2025-09-24T11:11:13.395427Z"
    }
   },
   "source": [
    "# Imports for text chunking\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "print(\"Text chunking tools imported!\")\n",
    "print(f\" Starting with {len(documents)} documents from Part 1\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text chunking tools imported!\n",
      " Starting with 85 documents from Part 1\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Chunking Strategy\n",
    "\n",
    "**Industry Best Practice**: 1000 characters with 200 overlap\n",
    "- **Why 1000 chars?** Perfect balance for embedding models\n",
    "- **Why 200 overlap?** Preserves context across chunks\n",
    "- **Recursive splitting**: Tries sentences, then words, then characters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:11:17.090077Z",
     "start_time": "2025-09-24T11:11:17.061235Z"
    }
   },
   "source": [
    "def create_smart_chunks(documents: List[Document]) -> List[Document]:\n",
    "    \"\"\"Split documents into optimal chunks for RAG\"\"\"\n",
    "    \n",
    "    print(\" Creating smart chunks...\")\n",
    "    \n",
    "    # Industry-standard chunking settings\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,        # Optimal for embedding models\n",
    "        chunk_overlap=200,      # Preserve context\n",
    "        length_function=len,    # Character-based\n",
    "        separators=[            # Try these in order:\n",
    "            \"\\n\\n\",              # Paragraphs first\n",
    "            \"\\n\",                # Then lines\n",
    "            \". \",                # Then sentences\n",
    "            \" \",                 # Then words\n",
    "            \"\",                  # Finally characters\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    all_chunks = []\n",
    "    stats = {\n",
    "        \"original_docs\": len(documents),\n",
    "        \"total_chunks\": 0,\n",
    "        \"by_department\": {},\n",
    "        \"by_file_type\": {}\n",
    "    }\n",
    "    \n",
    "    # Process each department\n",
    "    for dept in set(doc.metadata['department'] for doc in documents):\n",
    "        dept_docs = [doc for doc in documents if doc.metadata['department'] == dept]\n",
    "        dept_chunks = []\n",
    "        \n",
    "        print(f\" {dept}: {len(dept_docs)} docs â†’ \", end=\"\")\n",
    "        \n",
    "        for doc in dept_docs:\n",
    "            # Split the document\n",
    "            chunks = text_splitter.split_documents([doc])\n",
    "            \n",
    "            # Add chunk metadata\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                chunk.metadata.update({\n",
    "                    \"chunk_id\": f\"{doc.metadata['source_file']}_{i}\",\n",
    "                    \"chunk_index\": i,\n",
    "                    \"total_chunks\": len(chunks),\n",
    "                    \"chunk_size\": len(chunk.page_content)\n",
    "                })\n",
    "            \n",
    "            dept_chunks.extend(chunks)\n",
    "            \n",
    "            # Track stats\n",
    "            file_type = doc.metadata.get('file_type', 'unknown')\n",
    "            stats[\"by_file_type\"][file_type] = stats[\"by_file_type\"].get(file_type, 0) + len(chunks)\n",
    "        \n",
    "        stats[\"by_department\"][dept] = len(dept_chunks)\n",
    "        stats[\"total_chunks\"] += len(dept_chunks)\n",
    "        all_chunks.extend(dept_chunks)\n",
    "        \n",
    "        print(f\"{len(dept_chunks)} chunks\")\n",
    "    \n",
    "    print(f\"\\n CHUNKING COMPLETE:\")\n",
    "    print(f\"    Original: {stats['original_docs']} documents\")\n",
    "    print(f\"    Created: {stats['total_chunks']} chunks\")\n",
    "    print(f\"    Ratio: {stats['total_chunks'] / stats['original_docs']:.1f} chunks per document\")\n",
    "    \n",
    "    return all_chunks\n",
    "\n",
    "# Create chunks\n",
    "chunks = create_smart_chunks(documents)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Creating smart chunks...\n",
      " internal_operations: 3 docs â†’ 57 chunks\n",
      " legal_compliance: 28 docs â†’ 80 chunks\n",
      " customer_facing: 4 docs â†’ 82 chunks\n",
      " business_data: 50 docs â†’ 50 chunks\n",
      "\n",
      " CHUNKING COMPLETE:\n",
      "    Original: 85 documents\n",
      "    Created: 269 chunks\n",
      "    Ratio: 3.2 chunks per document\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Chunk Quality"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:11:24.664991Z",
     "start_time": "2025-09-24T11:11:24.645904Z"
    }
   },
   "source": [
    "def analyze_chunk_quality(chunks: List[Document]):\n",
    "    \"\"\"Analyze chunk distribution and quality\"\"\"\n",
    "    \n",
    "    print(\" CHUNK QUALITY ANALYSIS\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Size analysis\n",
    "    sizes = [len(chunk.page_content) for chunk in chunks]\n",
    "    avg_size = sum(sizes) / len(sizes)\n",
    "    min_size = min(sizes)\n",
    "    max_size = max(sizes)\n",
    "    \n",
    "    print(f\"Size Distribution:\")\n",
    "    print(f\"   Average: {avg_size:.0f} characters\")\n",
    "    print(f\"   Range: {min_size} - {max_size} characters\")\n",
    "    \n",
    "    # Size buckets\n",
    "    buckets = {\n",
    "        \"Small (0-500)\": sum(1 for s in sizes if s <= 500),\n",
    "        \"Medium (500-1000)\": sum(1 for s in sizes if 500 < s <= 1000),\n",
    "        \"Large (1000+)\": sum(1 for s in sizes if s > 1000)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n Size Distribution:\")\n",
    "    for bucket, count in buckets.items():\n",
    "        percentage = (count / len(chunks)) * 100\n",
    "        print(f\"   {bucket}: {count} chunks ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Department distribution\n",
    "    by_dept = {}\n",
    "    for chunk in chunks:\n",
    "        dept = chunk.metadata['department']\n",
    "        by_dept[dept] = by_dept.get(dept, 0) + 1\n",
    "    \n",
    "    print(f\"\\n By Department:\")\n",
    "    for dept, count in sorted(by_dept.items()):\n",
    "        percentage = (count / len(chunks)) * 100\n",
    "        print(f\"   {dept}: {count} chunks ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Quality assessment\n",
    "    optimal_chunks = sum(1 for s in sizes if 500 <= s <= 1000)\n",
    "    quality_score = (optimal_chunks / len(chunks)) * 100\n",
    "    \n",
    "    print(f\"\\n Quality Score: {quality_score:.1f}%\")\n",
    "    print(f\"   ({optimal_chunks}/{len(chunks)} chunks in optimal range)\")\n",
    "    \n",
    "    if quality_score >= 70:\n",
    "        print(\" Excellent chunking quality!\")\n",
    "    elif quality_score >= 50:\n",
    "        print(\" Good chunking quality\")\n",
    "    else:\n",
    "        print(\"ï¸ Consider adjusting chunk size\")\n",
    "\n",
    "analyze_chunk_quality(chunks)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CHUNK QUALITY ANALYSIS\n",
      "------------------------------\n",
      "Size Distribution:\n",
      "   Average: 661 characters\n",
      "   Range: 3 - 998 characters\n",
      "\n",
      " Size Distribution:\n",
      "   Small (0-500): 86 chunks (32.0%)\n",
      "   Medium (500-1000): 183 chunks (68.0%)\n",
      "   Large (1000+): 0 chunks (0.0%)\n",
      "\n",
      " By Department:\n",
      "   business_data: 50 chunks (18.6%)\n",
      "   customer_facing: 82 chunks (30.5%)\n",
      "   internal_operations: 57 chunks (21.2%)\n",
      "   legal_compliance: 80 chunks (29.7%)\n",
      "\n",
      " Quality Score: 68.0%\n",
      "   (183/269 chunks in optimal range)\n",
      " Good chunking quality\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Chunks Review"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:11:31.533111Z",
     "start_time": "2025-09-24T11:11:31.519876Z"
    }
   },
   "source": [
    "# Show sample chunks from different departments\n",
    "print(\" SAMPLE CHUNKS REVIEW\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "departments = list(set(chunk.metadata['department'] for chunk in chunks))\n",
    "\n",
    "for dept in departments[:3]:  # Show first 3 departments\n",
    "    dept_chunks = [c for c in chunks if c.metadata['department'] == dept]\n",
    "    if dept_chunks:\n",
    "        sample = dept_chunks[0]  # First chunk from department\n",
    "        \n",
    "        print(f\"\\n{dept.upper()}:\")\n",
    "        print(f\"   File: {sample.metadata['source_file']}\")\n",
    "        print(f\"   Size: {len(sample.page_content)} chars\")\n",
    "        print(f\"   Preview: {sample.page_content[:150]}...\")\n",
    "        print(f\"   Metadata: {sample.metadata['chunk_id']}\")\n",
    "\n",
    "print(f\"\\n Total chunks ready for vector storage: {len(chunks)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SAMPLE CHUNKS REVIEW\n",
      "-------------------------\n",
      "\n",
      "BUSINESS_DATA:\n",
      "   File: integration_partners.csv\n",
      "   Size: 303 chars\n",
      "   Preview: Partner_Name: Salesforce\n",
      "Integration_Type: CRM\n",
      "Setup_Difficulty: 3\n",
      "Support_Level: Full\n",
      "Documentation_Link: https://docs.dataflow.com/salesforce\n",
      "Certif...\n",
      "   Metadata: integration_partners.csv_0\n",
      "\n",
      "LEGAL_COMPLIANCE:\n",
      "   File: compliance_certifications.csv\n",
      "   Size: 276 chars\n",
      "   Preview: Certification: SOC 2 Type II\n",
      "Status: Compliant\n",
      "Date_Achieved: 2024-01-15\n",
      "Renewal_Date: 2026-01-15\n",
      "Audit_Frequency: Annual\n",
      "Last_Audit_Result: Pass\n",
      "Busi...\n",
      "   Metadata: compliance_certifications.csv_0\n",
      "\n",
      "CUSTOMER_FACING:\n",
      "   File: competitive_analysis.txt\n",
      "   Size: 877 chars\n",
      "   Preview: DataFlow Solutions Competitive Analysis\n",
      "Last Updated: June 8, 2025\n",
      "\n",
      "This document analyzes DataFlow Solutionsâ€™ position in the SaaS BI and data visual...\n",
      "   Metadata: competitive_analysis.txt_0\n",
      "\n",
      " Total chunks ready for vector storage: 269\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:11:35.734185Z",
     "start_time": "2025-09-24T11:11:35.718457Z"
    }
   },
   "source": [
    "# Validate chunking success\n",
    "print(\"ðŸ” CHUNKING VALIDATION\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Basic checks\n",
    "total_original_chars = sum(len(doc.page_content) for doc in documents)\n",
    "total_chunk_chars = sum(len(chunk.page_content) for chunk in chunks)\n",
    "content_preserved = (total_chunk_chars / total_original_chars) * 100\n",
    "\n",
    "checks = [\n",
    "    (len(chunks) > len(documents), f\"More chunks than docs: {len(chunks)} > {len(documents)}\"),\n",
    "    (content_preserved >= 90, f\"Content preserved: {content_preserved:.1f}%\"),\n",
    "    (all('chunk_id' in c.metadata for c in chunks), \"All chunks have IDs\"),\n",
    "    (all('department' in c.metadata for c in chunks), \"All chunks have departments\")\n",
    "]\n",
    "\n",
    "all_passed = True\n",
    "for passed, message in checks:\n",
    "    status = \"pass\" if passed else \"fail\"\n",
    "    print(f\"   {status} {message}\")\n",
    "    if not passed:\n",
    "        all_passed = False\n",
    "\n",
    "if all_passed:\n",
    "    print(\"\\nSUCCESS! Chunks ready for Part 3: Vector Embeddings\")\n",
    "else:\n",
    "    print(\"\\n Some validation checks failed\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” CHUNKING VALIDATION\n",
      "--------------------\n",
      "   pass More chunks than docs: 269 > 85\n",
      "   pass Content preserved: 106.2%\n",
      "   pass All chunks have IDs\n",
      "   pass All chunks have departments\n",
      "\n",
      "SUCCESS! Chunks ready for Part 3: Vector Embeddings\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Vector Embeddings & Search\n",
    "\n",
    "**Goal**: Transform text chunks into searchable mathematical vectors\n",
    "**Why Critical**: This enables semantic search - finding meaning, not just keywords\n",
    "\n",
    "\n",
    "Then run: `pip install sentence-transformers==4.1.0 huggingface-hub==0.32.4 langchain-huggingface`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:11:39.719019Z",
     "start_time": "2025-09-24T11:11:39.708879Z"
    }
   },
   "source": [
    "# Modern imports (no deprecation warnings)\n",
    "try:\n",
    "    # Modern approach - no deprecation warnings\n",
    "    from langchain_huggingface import HuggingFaceEmbeddings\n",
    "    print(\" Using modern langchain-huggingface (recommended)\")\n",
    "    modern_import = True\n",
    "except ImportError:\n",
    "    # Fallback to deprecated version if needed\n",
    "    from langchain.embeddings import HuggingFaceEmbeddings\n",
    "    print(\" Using deprecated import (consider upgrading)\")\n",
    "    print(\" Run: pip install langchain-huggingface\")\n",
    "    modern_import = False\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "print(\" Vector tools imported!\")\n",
    "print(f\"Ready to embed {len(chunks)} chunks from Part 2\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using modern langchain-huggingface (recommended)\n",
      " Vector tools imported!\n",
      "Ready to embed 269 chunks from Part 2\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Embedding Model\n",
    "\n",
    "**Model Choice**: `all-MiniLM-L6-v2`\n",
    "- **Fast**: Perfect for development and production\n",
    "- **Accurate**: Great semantic understanding\n",
    "- **Compact**: 384 dimensions (vs 1536 for OpenAI)\n",
    "- **Free**: No API costs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:11:47.720849Z",
     "start_time": "2025-09-24T11:11:43.059155Z"
    }
   },
   "source": [
    "def setup_embedding_model():\n",
    "    \"\"\"Initialize the embedding model for vector creation\"\"\"\n",
    "    \n",
    "    print(\"Loading embedding model...\")\n",
    "    \n",
    "    # Use production-grade embedding model\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    \n",
    "    # Modern LangChain wrapper (no deprecation warnings)\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs={'device': 'cpu'},  # Use CPU for compatibility\n",
    "        encode_kwargs={'normalize_embeddings': True}  # Better for similarity search\n",
    "    )\n",
    "    \n",
    "    print(f\"Model loaded: {model_name}\")\n",
    "    print(f\"Vector dimensions: 384\")\n",
    "    print(f\"Device: CPU (production compatible)\")\n",
    "    \n",
    "    if modern_import:\n",
    "        print(\" Using modern non-deprecated embeddings!\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Setup embeddings\n",
    "embeddings = setup_embedding_model()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "Model loaded: sentence-transformers/all-MiniLM-L6-v2\n",
      "Vector dimensions: 384\n",
      "Device: CPU (production compatible)\n",
      " Using modern non-deprecated embeddings!\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Store\n",
    "\n",
    "**FAISS**: Facebook's vector search library\n",
    "- Powers Instagram recommendations\n",
    "- Billion-scale vector search\n",
    "- Lightning-fast similarity search\n",
    "- Industry standard for RAG systems"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:12:08.575109Z",
     "start_time": "2025-09-24T11:11:55.189385Z"
    }
   },
   "source": [
    "def create_vector_store(chunks: List, embeddings) -> FAISS:\n",
    "    \"\"\"Create FAISS vector store from text chunks\"\"\"\n",
    "    \n",
    "    print(\" Creating vector embeddings...\")\n",
    "    print(\" This may take 30-60 seconds...\")\n",
    "    \n",
    "    # Create vector store with FAISS\n",
    "    vector_store = FAISS.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    \n",
    "    print(f\" Vector store created!\")\n",
    "    print(f\" Vectors: {len(chunks)}\")\n",
    "    print(f\" Dimensions: 384 per vector\")\n",
    "    print(f\"Total size: ~{len(chunks) * 384 * 4 / 1024 / 1024:.1f} MB\")\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "# Create the vector store\n",
    "vector_store = create_vector_store(chunks, embeddings)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Creating vector embeddings...\n",
      " This may take 30-60 seconds...\n",
      " Vector store created!\n",
      " Vectors: 269\n",
      " Dimensions: 384 per vector\n",
      "Total size: ~0.4 MB\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:12:12.554544Z",
     "start_time": "2025-09-24T11:12:12.407633Z"
    }
   },
   "source": [
    "def test_semantic_search(vector_store: FAISS, test_queries: List[str]):\n",
    "    \"\"\"Test the vector store with realistic customer queries\"\"\"\n",
    "    \n",
    "    print(\" TESTING SEMANTIC SEARCH\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\n Query {i}: '{query}'\")\n",
    "        \n",
    "        # Search for most relevant chunks\n",
    "        results = vector_store.similarity_search(\n",
    "            query=query, \n",
    "            k=3  # Top 3 most relevant chunks\n",
    "        )\n",
    "        \n",
    "        print(f\" Found {len(results)} relevant chunks:\")\n",
    "        \n",
    "        for j, result in enumerate(results, 1):\n",
    "            dept = result.metadata['department']\n",
    "            file = result.metadata['source_file']\n",
    "            preview = result.page_content[:100].replace('\\n', ' ')\n",
    "            \n",
    "            print(f\"   {j}.  {dept} |  {file}\")\n",
    "            print(f\"      Preview: {preview}...\")\n",
    "\n",
    "# Test with realistic customer queries\n",
    "test_queries = [\n",
    "    \"What are your pricing plans?\",\n",
    "    \"How do I integrate with your API?\",\n",
    "    \"What is your privacy policy?\",\n",
    "    \"I'm having trouble with authentication\",\n",
    "    \"Employee handbook and HR policies\"\n",
    "]\n",
    "\n",
    "test_semantic_search(vector_store, test_queries)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TESTING SEMANTIC SEARCH\n",
      "------------------------------\n",
      "\n",
      " Query 1: 'What are your pricing plans?'\n",
      " Found 3 relevant chunks:\n",
      "   1.  customer_facing |  competitive_analysis.txt\n",
      "      Preview: **Pricing**: - Pro: $10/user/month, Premium: $20/user/month, Premium Capacity: $4,995/month. - DataF...\n",
      "   2.  legal_compliance |  terms_of_service.markdown\n",
      "      Preview: 3.2 Payment Terms - **Methods**: Credit card, invoice, ACH for Enterprise (billing_and_pricing.csv)....\n",
      "   3.  customer_facing |  terms_of_service.markdown\n",
      "      Preview: 3.2 Payment Terms - **Methods**: Credit card, invoice, ACH for Enterprise (billing_and_pricing.csv)....\n",
      "\n",
      " Query 2: 'How do I integrate with your API?'\n",
      " Found 3 relevant chunks:\n",
      "   1.  customer_facing |  product_user_guide.markdown\n",
      "      Preview: ### 10.4 References - API Documentation: `api_documentation.json` - Troubleshooting Guide: `troubles...\n",
      "   2.  internal_operations |  system_architecture.markdown\n",
      "      Preview: ---  ## 3. API Gateway and Microservices The platform uses an API Gateway and microservices architec...\n",
      "   3.  internal_operations |  system_architecture.markdown\n",
      "      Preview: ### 3.2 Microservices - **Orchestration**: Kubernetes on Amazon EKS, 50 pods across 3 availability z...\n",
      "\n",
      " Query 3: 'What is your privacy policy?'\n",
      " Found 3 relevant chunks:\n",
      "   1.  internal_operations |  employee_handbook.txt\n",
      "      Preview: 2.2 Anti-Harassment We maintain a zero-tolerance policy for harassment, including verbal, physical, ...\n",
      "   2.  legal_compliance |  privacy_policy.txt\n",
      "      Preview: DataFlow Solutions Privacy Policy Last Updated: June 8, 2025  This Privacy Policy outlines how DataF...\n",
      "   3.  legal_compliance |  terms_of_service.markdown\n",
      "      Preview: This agreement incorporates our Privacy Policy (privacy_policy.txt), Security Policies (security_pol...\n",
      "\n",
      " Query 4: 'I'm having trouble with authentication'\n",
      " Found 3 relevant chunks:\n",
      "   1.  customer_facing |  troubleshooting_guide.txt\n",
      "      Preview: ---  7. API Authentication Failure Error Code: API-4001 Error Message: \"401: Unauthorized\" Descripti...\n",
      "   2.  legal_compliance |  security_policies.txt\n",
      "      Preview: 1.2 2FA Policy - Mandatory for all employees and customers (product_user_guide.md, Section 2.2). - U...\n",
      "   3.  customer_facing |  troubleshooting_guide.txt\n",
      "      Preview: ---  16. SSO Login Failure Error Code: SSO-9001 Error Message: \"SSO login failed: Invalid configurat...\n",
      "\n",
      " Query 5: 'Employee handbook and HR policies'\n",
      " Found 3 relevant chunks:\n",
      "   1.  internal_operations |  employee_handbook.txt\n",
      "      Preview: ---  3. Remote Work and Flexible Schedules DataFlow supports hybrid and remote work for 80% of emplo...\n",
      "   2.  legal_compliance |  privacy_policy.txt\n",
      "      Preview: 8.2 Organizational Measures - Employee training: Annual GDPR/CCPA training (employee_handbook.txt, S...\n",
      "   3.  legal_compliance |  security_policies.txt\n",
      "      Preview: ---  References - Employee Handbook: employee_handbook.txt - Compliance Certifications: compliance_c...\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:12:19.459974Z",
     "start_time": "2025-09-24T11:12:19.373046Z"
    }
   },
   "source": [
    "def analyze_search_quality(vector_store: FAISS):\n",
    "    \"\"\"Analyze the quality and coverage of semantic search\"\"\"\n",
    "    \n",
    "    print(\" SEARCH QUALITY ANALYSIS\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Test queries for each department\n",
    "    dept_queries = {\n",
    "        \"business_data\": \"pricing and billing information\",\n",
    "        \"customer_facing\": \"product features and user guide\",\n",
    "        \"internal_operations\": \"employee policies and procedures\", \n",
    "        \"legal_compliance\": \"privacy and terms of service\"\n",
    "    }\n",
    "    \n",
    "    coverage_score = 0\n",
    "    total_tests = len(dept_queries)\n",
    "    \n",
    "    for dept, query in dept_queries.items():\n",
    "        print(f\"\\n Testing {dept} coverage...\")\n",
    "        \n",
    "        results = vector_store.similarity_search(query, k=5)\n",
    "        \n",
    "        # Check if top results are from the right department\n",
    "        dept_matches = sum(1 for r in results if r.metadata['department'] == dept)\n",
    "        accuracy = (dept_matches / len(results)) * 100 if results else 0\n",
    "        \n",
    "        print(f\"   Query: '{query}'\")\n",
    "        print(f\"   Accuracy: {dept_matches}/{len(results)} = {accuracy:.1f}%\")\n",
    "        \n",
    "        if accuracy >= 60:  # At least 3/5 results from correct dept\n",
    "            coverage_score += 1\n",
    "            print(f\"   Good coverage\")\n",
    "        else:\n",
    "            print(f\"    Needs improvement\")\n",
    "    \n",
    "    overall_score = (coverage_score / total_tests) * 100\n",
    "    \n",
    "    print(f\"\\n OVERALL SEARCH QUALITY: {overall_score:.1f}%\")\n",
    "    print(f\"   ({coverage_score}/{total_tests} departments with good coverage)\")\n",
    "    \n",
    "    if overall_score >= 75:\n",
    "        print(\" Excellent search quality!\")\n",
    "    elif overall_score >= 50:\n",
    "        print(\" Good search quality\")\n",
    "    else:\n",
    "        print(\" Consider more diverse chunks or better embeddings\")\n",
    "    \n",
    "    return overall_score\n",
    "\n",
    "quality_score = analyze_search_quality(vector_store)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SEARCH QUALITY ANALYSIS\n",
      "------------------------------\n",
      "\n",
      " Testing business_data coverage...\n",
      "   Query: 'pricing and billing information'\n",
      "   Accuracy: 0/5 = 0.0%\n",
      "    Needs improvement\n",
      "\n",
      " Testing customer_facing coverage...\n",
      "   Query: 'product features and user guide'\n",
      "   Accuracy: 2/5 = 40.0%\n",
      "    Needs improvement\n",
      "\n",
      " Testing internal_operations coverage...\n",
      "   Query: 'employee policies and procedures'\n",
      "   Accuracy: 2/5 = 40.0%\n",
      "    Needs improvement\n",
      "\n",
      " Testing legal_compliance coverage...\n",
      "   Query: 'privacy and terms of service'\n",
      "   Accuracy: 4/5 = 80.0%\n",
      "   Good coverage\n",
      "\n",
      " OVERALL SEARCH QUALITY: 25.0%\n",
      "   (1/4 departments with good coverage)\n",
      " Consider more diverse chunks or better embeddings\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:12:28.831891Z",
     "start_time": "2025-09-24T11:12:28.804879Z"
    }
   },
   "source": [
    "# Save vector store for production use\n",
    "def save_vector_store(vector_store: FAISS, save_path: str = \"dataflow_vector_store\"):\n",
    "    \"\"\"Save vector store to disk for reuse\"\"\"\n",
    "    \n",
    "    print(f\"ðŸ’¾ Saving vector store to '{save_path}'...\")\n",
    "    \n",
    "    try:\n",
    "        vector_store.save_local(save_path)\n",
    "        print(f\"Vector store saved successfully!\")\n",
    "        print(f\"Location: {save_path}/\")\n",
    "        print(f\" Can be loaded later with: FAISS.load_local('{save_path}', embeddings)\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Save failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Save the vector store\n",
    "save_success = save_vector_store(vector_store)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Saving vector store to 'dataflow_vector_store'...\n",
      "Vector store saved successfully!\n",
      "Location: dataflow_vector_store/\n",
      " Can be loaded later with: FAISS.load_local('dataflow_vector_store', embeddings)\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:12:31.960759Z",
     "start_time": "2025-09-24T11:12:31.916724Z"
    }
   },
   "source": [
    "# Final validation\n",
    "print(\" VECTOR STORE VALIDATION\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Test basic functionality\n",
    "test_query = \"pricing information\"\n",
    "test_results = vector_store.similarity_search(test_query, k=1)\n",
    "\n",
    "checks = [\n",
    "    (len(test_results) > 0, \"Vector search returns results\"),\n",
    "    (hasattr(vector_store, 'index'), \"FAISS index created\"),\n",
    "    (save_success, \"Vector store saved successfully\"),\n",
    "    (len(chunks) > 0, f\"All {len(chunks)} chunks embedded\"),\n",
    "    (modern_import, \"Using modern non-deprecated imports\")\n",
    "]\n",
    "\n",
    "all_passed = True\n",
    "for passed, message in checks:\n",
    "    status = \"pass\" if passed else \"fail\"\n",
    "    print(f\"   {status} {message}\")\n",
    "    if not passed:\n",
    "        all_passed = False\n",
    "\n",
    "if all_passed:\n",
    "    print(\"\\n SUCCESS! Vector store ready for Part 4: RAG Agent\")\n",
    "    print(\" You now have a production-grade semantic search system!\")\n",
    "    print(f\" Search quality: {quality_score:.1f}% accuracy\")\n",
    "else:\n",
    "    print(\"\\nï¸ Some validation checks failed\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " VECTOR STORE VALIDATION\n",
      "-------------------------\n",
      "   pass Vector search returns results\n",
      "   pass FAISS index created\n",
      "   pass Vector store saved successfully\n",
      "   pass All 269 chunks embedded\n",
      "   pass Using modern non-deprecated imports\n",
      "\n",
      " SUCCESS! Vector store ready for Part 4: RAG Agent\n",
      " You now have a production-grade semantic search system!\n",
      " Search quality: 25.0% accuracy\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: RAG Agent - Complete Intelligent System\n",
    "\n",
    "**Goal**: Connect vector search to LLM for intelligent customer service\n",
    "\n",
    "\n",
    "\n",
    "## LLM Setup Required\n",
    "**Ollama (Free, Local)**\n",
    "```bash\n",
    "# Install Ollama from https://ollama.ai\n",
    "ollama pull llama3.2  # Download model\n",
    "ollama serve         # Start server\n",
    "```\n",
    "\n",
    "**Alternative: OpenAI (if you prefer)**\n",
    "```bash\n",
    "pip install openai\n",
    "# Set OPENAI_API_KEY environment variable\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:10:28.385736Z",
     "start_time": "2025-09-24T11:10:28.301096Z"
    }
   },
   "source": [
    "# Imports for RAG agent\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "import time\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Simple Ollama setup\n",
    "llm = None\n",
    "\n",
    "try:\n",
    "    from langchain.llms import Ollama\n",
    "    llm = Ollama(model=\"llama3.2\", base_url=\"http://localhost:11434\")\n",
    "    # Test connection\n",
    "    test_response = llm.invoke(\"Hello\")\n",
    "    print(\" Ollama LLM connected successfully!\")\n",
    "    print(\"Using free local LLM\")\n",
    "    print(f\"Vector store ready: {len(chunks)} chunks\")\n",
    "except Exception as e:\n",
    "    print(f\" Ollama connection failed: {e}\")\n",
    "    print(\" Make sure Ollama is running: ollama serve\")\n",
    "    print(\" And model is downloaded: ollama pull llama3.2\")\n",
    "    llm = None"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Customer Service Prompt"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:26:00.894455Z",
     "start_time": "2025-09-24T11:26:00.884699Z"
    }
   },
   "source": [
    "# Professional customer service prompt\n",
    "CUSTOMER_SERVICE_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"You are DataFlow's helpful customer service assistant. Your job is to provide accurate, friendly, and professional support to customers.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Use the provided context to answer questions accurately\n",
    "- Be concise but thorough in your explanations\n",
    "- If information isn't in the context, say \"I don't have that specific information\" and suggest contacting support\n",
    "- Always maintain a helpful and professional tone\n",
    "- For technical questions, provide step-by-step guidance when possible\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "CUSTOMER QUESTION:\n",
    "{question}\n",
    "\n",
    "RESPONSE:\"\"\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Professional customer service prompt created\")\n",
    "print(\"ðŸŽ¯ Optimized for helpful, accurate responses\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional customer service prompt created\n",
      " Optimized for helpful, accurate responses\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:39:48.074822Z",
     "start_time": "2025-09-24T11:39:48.065481Z"
    }
   },
   "source": [
    "def create_rag_chain(vector_store, llm, prompt_template):\n",
    "    \"\"\"Create production RAG chain\"\"\"\n",
    "\n",
    "    if not llm:\n",
    "        print(\" No LLM available - cannot create RAG chain\")\n",
    "        print(\" Please install Ollama or set up OpenAI API key\")\n",
    "        return None\n",
    "\n",
    "    print(\"ðŸ”— Creating RAG chain...\")\n",
    "\n",
    "    # Create retrieval QA chain\n",
    "    rag_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",  # Stuff all context into prompt\n",
    "        retriever=vector_store.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 4}  # Retrieve top 4 most relevant chunks\n",
    "        ),\n",
    "        chain_type_kwargs={\n",
    "            \"prompt\": prompt_template\n",
    "        },\n",
    "        return_source_documents=True  # Show which documents were used\n",
    "    )\n",
    "\n",
    "    print(\" RAG chain created successfully!\")\n",
    "    print(\" Retriever: Top 4 most relevant chunks\")\n",
    "    print(\" LLM: Ready for customer questions\")\n",
    "    print(\" Source attribution: Enabled\")\n",
    "\n",
    "    return rag_chain\n",
    "\n",
    "# Create the RAG chain\n",
    "rag_chain = create_rag_chain(vector_store, llm, CUSTOMER_SERVICE_PROMPT)"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Service Agent"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:43:02.547068Z",
     "start_time": "2025-09-24T11:43:02.522273Z"
    }
   },
   "source": [
    "class DataFlowCustomerAgent:\n",
    "    \"\"\"Professional customer service agent with simple conversation tracking\"\"\"\n",
    "\n",
    "    def __init__(self, rag_chain):\n",
    "        self.rag_chain = rag_chain\n",
    "        # Simple conversation tracking (no deprecated memory)\n",
    "        self.conversation_history = []\n",
    "        self.conversation_count = 0\n",
    "        self.response_times = []\n",
    "\n",
    "        print(\"ðŸ¤– DataFlow Customer Service Agent initialized\")\n",
    "\n",
    "    def ask(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Ask the agent a question and get a comprehensive response\"\"\"\n",
    "\n",
    "        if not self.rag_chain:\n",
    "            return {\n",
    "                \"answer\": \"I'm sorry, but I'm not properly configured right now. Please contact our support team directly.\",\n",
    "                \"sources\": [],\n",
    "                \"response_time\": 0,\n",
    "                \"error\": \"No LLM available\"\n",
    "            }\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            # Get response from RAG chain\n",
    "            response = self.rag_chain.invoke({\"query\": question})\n",
    "\n",
    "            end_time = time.time()\n",
    "            response_time = end_time - start_time\n",
    "\n",
    "            # Simple conversation tracking\n",
    "            self.conversation_history.append({\n",
    "                \"question\": question,\n",
    "                \"answer\": response[\"result\"],\n",
    "                \"timestamp\": start_time\n",
    "            })\n",
    "\n",
    "            # Track metrics\n",
    "            self.conversation_count += 1\n",
    "            self.response_times.append(response_time)\n",
    "\n",
    "            # Extract source information\n",
    "            sources = []\n",
    "            if \"source_documents\" in response:\n",
    "                for doc in response[\"source_documents\"]:\n",
    "                    sources.append({\n",
    "                        \"department\": doc.metadata.get(\"department\", \"unknown\"),\n",
    "                        \"file\": doc.metadata.get(\"source_file\", \"unknown\"),\n",
    "                        \"preview\": doc.page_content[:100] + \"...\"\n",
    "                    })\n",
    "\n",
    "            return {\n",
    "                \"answer\": response[\"result\"],\n",
    "                \"sources\": sources,\n",
    "                \"response_time\": response_time,\n",
    "                \"conversation_turn\": self.conversation_count\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"answer\": f\"I apologize, but I encountered an error. Please try rephrasing or contact support.\",\n",
    "                \"sources\": [],\n",
    "                \"response_time\": time.time() - start_time,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get agent performance statistics\"\"\"\n",
    "\n",
    "        if not self.response_times:\n",
    "            return {\"conversations\": 0, \"avg_response_time\": 0}\n",
    "\n",
    "        return {\n",
    "            \"conversations\": self.conversation_count,\n",
    "            \"avg_response_time\": sum(self.response_times) / len(self.response_times),\n",
    "            \"fastest_response\": min(self.response_times),\n",
    "            \"slowest_response\": max(self.response_times),\n",
    "            \"total_history\": len(self.conversation_history)\n",
    "        }\n",
    "\n",
    "    def get_conversation_history(self, last_n: int = 5):\n",
    "        \"\"\"Get recent conversation history\"\"\"\n",
    "        return self.conversation_history[-last_n:] if self.conversation_history else []\n",
    "\n",
    "# Create the customer service agent\n",
    "agent = DataFlowCustomerAgent(rag_chain)\n",
    "print(\"âœ… Customer service agent ready!\")"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Customer Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:48:08.183188Z",
     "start_time": "2025-09-24T11:48:08.162895Z"
    }
   },
   "source": [
    "def test_customer_scenarios(agent):\n",
    "    \"\"\"Test agent with realistic customer service scenarios\"\"\"\n",
    "\n",
    "    print(\" TESTING CUSTOMER SERVICE SCENARIOS\")\n",
    "    print(\"=\" * 45)\n",
    "\n",
    "    # Realistic customer questions\n",
    "    scenarios = [\n",
    "        {\n",
    "            \"question\": \"What are your pricing plans and how much does the premium plan cost?\",\n",
    "            \"category\": \"Billing\",\n",
    "            \"expected_dept\": \"business_data\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How do I authenticate with your API? I'm getting authentication errors.\",\n",
    "            \"category\": \"Technical Support\",\n",
    "            \"expected_dept\": \"customer_facing\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What data do you collect and how do you protect my privacy?\",\n",
    "            \"category\": \"Privacy/Legal\",\n",
    "            \"expected_dept\": \"legal_compliance\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, scenario in enumerate(scenarios, 1):\n",
    "        print(f\"\\nðŸ“ž Scenario {i}: {scenario['category']}\")\n",
    "        print(f\"â“ Question: {scenario['question']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # Get agent response\n",
    "        response = agent.ask(scenario[\"question\"])\n",
    "\n",
    "        print(f\" Agent Response:\")\n",
    "        print(f\"   {response['answer']}\")  # Show complete response\n",
    "\n",
    "        print(f\"\\n Sources Used:\")\n",
    "        for j, source in enumerate(response['sources'][:3], 1):  # Show top 3 sources\n",
    "            print(f\"   {j}.  {source['department']} - {source['file']}\")\n",
    "\n",
    "        print(f\"\\n Response Time: {response['response_time']:.2f} seconds\")\n",
    "\n",
    "        # Check if correct department was used\n",
    "        dept_match = any(source['department'] == scenario['expected_dept'] for source in response['sources'])\n",
    "        accuracy = \"âœ… Accurate\" if dept_match else \" Needs Review\"\n",
    "        print(f\" Department Accuracy: {accuracy}\")\n",
    "\n",
    "        results.append({\n",
    "            \"scenario\": scenario,\n",
    "            \"response\": response,\n",
    "            \"accurate\": dept_match\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Test the scenarios\n",
    "test_results = test_customer_scenarios(agent)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ­ RUNNING CUSTOMER SCENARIOS\n",
      "=============================================\n",
      "\n",
      "ðŸ“ž Scenario 1: Billing\n",
      "â“ Question: What are your pricing plans and how much does the premium plan cost?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Agent Response:\n",
      "   I'm sorry, but I'm not properly configured right now. Please contact our support team directly.\n",
      "\n",
      "ðŸ“š Sources Used:\n",
      "   âš ï¸ No sources provided\n",
      "\n",
      "â±ï¸ Response Time: 0.00 seconds\n",
      "ðŸŽ¯ Department Accuracy: âš ï¸ Needs Review\n",
      "\n",
      "ðŸ“ž Scenario 2: Technical Support\n",
      "â“ Question: How do I authenticate with your API? I'm getting authentication errors.\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Agent Response:\n",
      "   I'm sorry, but I'm not properly configured right now. Please contact our support team directly.\n",
      "\n",
      "ðŸ“š Sources Used:\n",
      "   âš ï¸ No sources provided\n",
      "\n",
      "â±ï¸ Response Time: 0.00 seconds\n",
      "ðŸŽ¯ Department Accuracy: âš ï¸ Needs Review\n",
      "\n",
      "ðŸ“ž Scenario 3: Privacy/Legal\n",
      "â“ Question: What data do you collect and how do you protect my privacy?\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Agent Response:\n",
      "   I'm sorry, but I'm not properly configured right now. Please contact our support team directly.\n",
      "\n",
      "ðŸ“š Sources Used:\n",
      "   âš ï¸ No sources provided\n",
      "\n",
      "â±ï¸ Response Time: 0.00 seconds\n",
      "ðŸŽ¯ Department Accuracy: âš ï¸ Needs Review\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:48:51.452429Z",
     "start_time": "2025-09-24T11:48:51.438029Z"
    }
   },
   "source": [
    "def calculate_business_impact(agent, test_results):\n",
    "    \"\"\"Calculate measurable business impact and ROI\"\"\"\n",
    "\n",
    "    print(\"BUSINESS IMPACT ANALYSIS\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    # Get agent performance stats\n",
    "    stats = agent.get_stats()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accurate_responses = sum(1 for result in test_results if result['accurate'])\n",
    "    accuracy_rate = (accurate_responses / len(test_results)) * 100 if test_results else 0\n",
    "\n",
    "    # Business metrics\n",
    "    metrics = {\n",
    "        \"daily_customer_questions\": 50,\n",
    "        \"avg_human_response_time\": 300,  # 5 minutes\n",
    "        \"hourly_support_cost\": 25,\n",
    "        \"working_days_per_year\": 250,\n",
    "        \"ai_accuracy_rate\": accuracy_rate,\n",
    "        \"ai_avg_response_time\": stats.get('avg_response_time', 0)\n",
    "    }\n",
    "\n",
    "    # Calculate savings\n",
    "    daily_human_hours = (metrics['daily_customer_questions'] * metrics['avg_human_response_time']) / 3600\n",
    "    daily_ai_hours = (metrics['daily_customer_questions'] * metrics['ai_avg_response_time']) / 3600\n",
    "\n",
    "    hours_saved_daily = daily_human_hours - daily_ai_hours\n",
    "    daily_cost_savings = hours_saved_daily * metrics['hourly_support_cost']\n",
    "    annual_savings = daily_cost_savings * metrics['working_days_per_year']\n",
    "\n",
    "    print(f\" PERFORMANCE METRICS:\")\n",
    "    print(f\"   Accuracy Rate: {accuracy_rate:.1f}%\")\n",
    "    print(f\"   Avg Response Time: {metrics['ai_avg_response_time']:.2f} seconds\")\n",
    "    print(f\"   Questions Handled: {stats.get('conversations', 0)}\")\n",
    "\n",
    "    print(f\"\\n COST ANALYSIS:\")\n",
    "    print(f\"   Human Response Time: {metrics['avg_human_response_time']} seconds avg\")\n",
    "    print(f\"   AI Response Time: {metrics['ai_avg_response_time']:.1f} seconds avg\")\n",
    "\n",
    "    print(f\"\\n BUSINESS IMPACT:\")\n",
    "    print(f\"   Hours Saved Daily: {hours_saved_daily:.1f} hours\")\n",
    "    print(f\"   Daily Cost Savings: ${daily_cost_savings:.2f}\")\n",
    "    print(f\"   Annual Cost Savings: ${annual_savings:,.2f}\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy_rate\": accuracy_rate,\n",
    "        \"annual_savings\": annual_savings,\n",
    "        \"hours_saved_daily\": hours_saved_daily\n",
    "    }\n",
    "\n",
    "# Calculate business impact\n",
    "business_impact = calculate_business_impact(agent, test_results)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’µ BUSINESS IMPACT SUMMARY\n",
      "========================================\n",
      "Accuracy Rate: 0.0%\n",
      "Avg Response Time: 0.00 seconds\n",
      "Hours Saved Daily: 4.2 hours\n",
      "Daily Cost Savings: $104.17\n",
      "Estimated Annual Savings: $26,041.67\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T11:47:15.202508Z",
     "start_time": "2025-09-24T11:47:15.150227Z"
    }
   },
   "source": [
    "# Final system validation\n",
    "print(\"ðŸ” FINAL SYSTEM VALIDATION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# System components check\n",
    "components = [\n",
    "    (len(chunks) > 0, f\"Document chunks loaded: {len(chunks)}\"),\n",
    "    (vector_store is not None, \"Vector store created\"),\n",
    "    (llm is not None, f\"LLM connected: {llm_type if llm else 'None'}\"),\n",
    "    (rag_chain is not None, \"RAG chain built\"),\n",
    "    (agent is not None, \"Customer service agent ready\")\n",
    "]\n",
    "\n",
    "all_systems_go = True\n",
    "for check, message in components:\n",
    "    status = \"âœ…\" if check else \"âŒ\"\n",
    "    print(f\"   {status} {message}\")\n",
    "    if not check:\n",
    "        all_systems_go = False\n",
    "\n",
    "# Performance validation\n",
    "if test_results:\n",
    "    accuracy = sum(1 for r in test_results if r['accurate']) / len(test_results) * 100\n",
    "    print(f\"\\n PERFORMANCE VALIDATION:\")\n",
    "    print(f\"   Accuracy Rate: {accuracy:.1f}%\")\n",
    "    print(f\"   esponse Time: {agent.get_stats().get('avg_response_time', 0):.2f}s avg\")\n",
    "    print(f\"    Business Impact: ${business_impact.get('annual_savings', 0):,.0f} annual savings\")\n",
    "\n",
    "if all_systems_go:\n",
    "    print(\"\\nSUCCESS! COMPLETE RAG SYSTEM OPERATIONAL\")\n",
    "    print(\" DataFlow's AI customer service agent is ready for production!\")\n",
    "\n",
    "    if business_impact.get('accuracy_rate', 0) >= 75:\n",
    "        print(\"â­ EXCELLENT: High accuracy + strong business case\")\n",
    "    elif business_impact.get('accuracy_rate', 0) >= 60:\n",
    "        print(\" GOOD: Solid foundation for customer service automation\")\n",
    "    else:\n",
    "        print(\"âš NEEDS IMPROVEMENT: Consider fine-tuning\")\n",
    "else:\n",
    "    print(\"\\nâš  PARTIAL SUCCESS: Some components need attention\")\n",
    "    print(\" Check LLM setup (Ollama or OpenAI) for full functionality\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” FINAL SYSTEM VALIDATION\n",
      "========================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'llm_wrapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[72], line 12\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Check system components\u001B[39;00m\n\u001B[1;32m      7\u001B[0m all_systems_go \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m      9\u001B[0m components \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     10\u001B[0m     (chunks \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(chunks) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDocument chunks loaded: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(chunks)\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mif\u001B[39;00m\u001B[38;5;250m \u001B[39mchunks\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01melse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m0\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     11\u001B[0m     (vector_store \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVector store created\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m---> 12\u001B[0m     (\u001B[43mllm_wrapper\u001B[49m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLLM connected: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mgetattr\u001B[39m(llm_wrapper,\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNone\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     13\u001B[0m     (rag_chain \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRAG chain built\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     14\u001B[0m     (agent \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCustomer service agent ready\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     15\u001B[0m ]\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m check, message \u001B[38;5;129;01min\u001B[39;00m components:\n\u001B[1;32m     18\u001B[0m     status \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mâœ…\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m check \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mâŒ\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'llm_wrapper' is not defined"
     ]
    }
   ],
   "execution_count": 72
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
